{
  "id": 5,
  "module": "sys",
  "slug": "data-partitioning-and-consistency",
  "title": "Data Partitioning & Consistency",
  "topics": [
    "Consistent hashing",
    "Quorum",
    "Strong vs eventual",
    "Gossip protocol"
  ],
  "estimatedReadMinutes": 10,
  "activities": [
    {
      "type": "spark",
      "title": "Consistent Hashing Ring Demo",
      "desc": "Use a physical ring (whiteboard circle) and sticky note 'nodes'. Add/remove nodes and see how keys redistribute. Count moves with/without virtual nodes.",
      "time": "20 min",
      "format": "Group"
    },
    {
      "type": "intro",
      "title": "Quorum Calculator",
      "desc": "Students calculate read quorum, write quorum, and fault tolerance for N=5, 7, 9 node clusters. Explore the R+W>N rule.",
      "time": "20 min",
      "format": "Solo"
    },
    {
      "type": "practice",
      "title": "Consistency Level Trade-off Table",
      "desc": "Create a 3-column table: scenario, recommended consistency level, justification. Fill in 6 real-world scenarios.",
      "time": "20 min",
      "format": "Pairs"
    },
    {
      "type": "assess",
      "title": "Gossip Protocol Trace",
      "desc": "Given a 6-node cluster with partial updates, trace how gossip spreads. Identify when all nodes converge.",
      "time": "15 min",
      "format": "Solo"
    }
  ],
  "activityTypes": [
    "spark",
    "intro",
    "practice",
    "assess"
  ],
  "sections": {
    "concepts": [
      {
        "heading": "What it is",
        "body": "Data Partitioning & Consistency covers the design decisions needed to build reliable systems and explain those decisions in interviews. The core focus is understanding Consistent hashing, Quorum, Strong vs eventual and linking each concept to an architecture consequence."
      },
      {
        "heading": "Why it matters in interviews",
        "body": "Interviewers expect you to justify trade-offs, not just list tools. For Data Partitioning & Consistency, strong answers connect constraints, architecture choices, and failure behavior while staying explicit about what you would de-scope first."
      }
    ],
    "architecture": {
      "components": [
        "Client",
        "API Gateway",
        "Core Service",
        "Cache",
        "Primary Database",
        "Message Queue",
        "Worker",
        "Monitoring"
      ],
      "flowSteps": [
        "Clarify scope and constraints for Data Partitioning & Consistency before choosing architecture primitives.",
        "Define boundaries for Consistent hashing and map request/write paths.",
        "Introduce resilience points such as retries, idempotency, and observability checkpoints.",
        "Evaluate bottlenecks under peak load or feature expansion assumptions.",
        "Capture final trade-offs and explain why rejected alternatives were not selected."
      ],
      "diagramAscii": "Client --> API Gateway --> Service Layer --> Cache\n                              |            |\n                              v            v\n                        Message Queue --> Workers\n                              |\n                              v\n                         Primary Database\n                              |\n                              v\n                           Monitoring"
    },
    "tradeoffs": [
      {
        "decision": "Consistency vs Availability",
        "optionA": "Strong consistency with synchronous coordination",
        "optionB": "Higher availability with eventual consistency",
        "chooseWhen": "Prefer option A for correctness-critical flows in Data Partitioning & Consistency; choose option B for read-heavy workloads with tolerant staleness.",
        "risk": "Choosing incorrectly can either over-complicate the stack or produce stale data under failures."
      },
      {
        "decision": "Latency vs Durability",
        "optionA": "Fast in-memory path with async persistence",
        "optionB": "Write-through path before ack",
        "chooseWhen": "Use fast path when user experience and throughput dominate; use durable path for financial or irreversible operations.",
        "risk": "Async persistence increases loss window; sync persistence increases tail latency."
      },
      {
        "decision": "Horizontal Scale vs Simplicity",
        "optionA": "Shard and partition early",
        "optionB": "Scale vertically and delay partitioning",
        "chooseWhen": "Adopt sharding when clear data volume growth exists; stay simple when traffic is modest and team size is small.",
        "risk": "Premature sharding raises ops burden; delaying too long can cause painful migrations."
      },
      {
        "decision": "Operational Cost vs Performance",
        "optionA": "Multi-region active-active setup",
        "optionB": "Single region plus disaster recovery",
        "chooseWhen": "Choose multi-region for strict global SLA and low-latency demands; choose single region to control cost and complexity.",
        "risk": "Multi-region introduces replication and consistency challenges; single-region increases outage blast radius."
      }
    ],
    "examples": [
      {
        "name": "Shopping Cart Replication",
        "context": "Shopping Cart Replication demands clear boundaries around Consistent hashing and predictable behavior during peak usage.",
        "designChoice": "Use a staged design with a fast path and a durable path, then expose explicit fallback behavior to callers.",
        "why": "This keeps latency stable for normal traffic while preserving correctness for critical writes and failure recovery."
      },
      {
        "name": "User Profile Sync",
        "context": "User Profile Sync introduces changing requirements and forces design updates without breaking existing clients.",
        "designChoice": "Introduce stable interfaces, versioned contracts, and observability from the start so changes remain testable.",
        "why": "You can iterate safely while preserving backward compatibility and maintaining confidence in production behavior."
      }
    ],
    "interviewQa": [
      {
        "question": "How would you design data partitioning & consistency for 10x growth?",
        "answerFramework": [
          "Clarify constraints and traffic shape",
          "Estimate scale and hotspots",
          "Propose baseline architecture",
          "Address bottlenecks and failure modes",
          "Explain final trade-offs"
        ]
      },
      {
        "question": "Which trade-off is most important in data partitioning & consistency and why?",
        "answerFramework": [
          "State competing goals",
          "Choose one based on business risk",
          "Describe mitigation for the rejected option",
          "Define monitoring signals",
          "Describe revisit trigger"
        ]
      },
      {
        "question": "How do you handle failures in Consistent hashing?",
        "answerFramework": [
          "Enumerate failure classes",
          "Add retries and idempotency boundaries",
          "Plan degraded behavior",
          "Protect data correctness",
          "Close with incident response approach"
        ]
      },
      {
        "question": "What would be your API and data model choices for data partitioning & consistency?",
        "answerFramework": [
          "List key entities",
          "Define read/write patterns",
          "Choose consistency level",
          "Define pagination or batching strategy",
          "Cover evolution and versioning"
        ]
      },
      {
        "question": "How would you explain this design to a senior interviewer in 5 minutes?",
        "answerFramework": [
          "Start with requirements",
          "Show architecture and data flow",
          "Highlight critical trade-offs",
          "Call out failure handling",
          "Suggest future improvements"
        ]
      }
    ],
    "revision": {
      "cheatSheet": [
        "Start every Data Partitioning & Consistency answer with assumptions and limits.",
        "Name one latency-sensitive path and one correctness-sensitive path.",
        "State how Consistent hashing is written and read under load.",
        "Explain one scaling strategy and one fallback strategy.",
        "Mention observability: metrics, logs, and tracing checkpoints.",
        "Call out a deliberate de-scope to keep MVP practical.",
        "Finish with what you would improve in version two."
      ],
      "redFlags": [
        "Choosing technology without linking it to constraints.",
        "Ignoring data consistency or idempotency for write operations.",
        "No failure-mode story for dependency outages.",
        "No plan to measure whether the design is actually working."
      ]
    }
  }
}
